{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following stopwords have been taken from NLTK\n",
    "\n",
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
    "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \n",
    "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \n",
    "              \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\",\n",
    "              \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\n",
    "              \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuations\n",
    "punctuations = [\".\", \"?\", \"\\\"\", \"'\", \",\", \"!\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"...\", \"/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "My name is Clark, and I will tell you about my city.\n",
    "\n",
    "I live in an apartment. In my city, there is a post office where people mail letters. On Monday, I go to work. I work at the post office. Everyone shops for food at the grocery store. They also eat at the restaurant. The restaurant serves pizza and ice cream.\n",
    "\n",
    "My friends and I go to the park. We like to play soccer at the park. On Fridays, we go to the cinema to see a movie. Children don't go to school on the weekend. Each day, people go to the hospital when they are sick. The doctors and nurses take care of them. The police keep everyone safe. I am happy to live in my city.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my name is clark and i will tell you about my city',\n",
       " 'i live in an apartment',\n",
       " 'in my city there is a post office where people mail letters',\n",
       " 'on monday i go to work',\n",
       " 'i work at the post office',\n",
       " 'everyone shops for food at the grocery store',\n",
       " 'they also eat at the restaurant',\n",
       " 'the restaurant serves pizza and ice cream',\n",
       " 'my friends and i go to the park',\n",
       " 'we like to play soccer at the park',\n",
       " 'on fridays we go to the cinema to see a movie',\n",
       " 'children dont go to school on the weekend',\n",
       " 'each day people go to the hospital when they are sick',\n",
       " 'the doctors and nurses take care of them',\n",
       " 'the police keep everyone safe',\n",
       " 'i am happy to live in my city']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.findall(r\"[^.?!]+\", text.strip())\n",
    "trim = lambda x : [\"\".join([c.lower() for c in x.strip() if c not in punctuations]) for x in x]\n",
    "trimmed_sentences = trim(sentences)\n",
    "trimmed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name clark tell city',\n",
       " 'live apartment',\n",
       " 'city post office people mail letters',\n",
       " 'monday go work',\n",
       " 'work post office',\n",
       " 'everyone shops food grocery store',\n",
       " 'also eat restaurant',\n",
       " 'restaurant serves pizza ice cream',\n",
       " 'friends go park',\n",
       " 'like play soccer park',\n",
       " 'fridays go cinema see movie',\n",
       " 'children dont go school weekend',\n",
       " 'day people go hospital sick',\n",
       " 'doctors nurses take care',\n",
       " 'police keep everyone safe',\n",
       " 'happy live city']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words = lambda x : [\" \".join([w for w in x.split() if w not in stop_words]) for x in x]\n",
    "normalized_sentences = remove_stop_words(trimmed_sentences)\n",
    "normalized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'clark',\n",
       " 'tell',\n",
       " 'city',\n",
       " 'live',\n",
       " 'apartment',\n",
       " 'city',\n",
       " 'post',\n",
       " 'office',\n",
       " 'people',\n",
       " 'mail',\n",
       " 'letters',\n",
       " 'monday',\n",
       " 'go',\n",
       " 'work',\n",
       " 'work',\n",
       " 'post',\n",
       " 'office',\n",
       " 'everyone',\n",
       " 'shops',\n",
       " 'food',\n",
       " 'grocery',\n",
       " 'store',\n",
       " 'also',\n",
       " 'eat',\n",
       " 'restaurant',\n",
       " 'restaurant',\n",
       " 'serves',\n",
       " 'pizza',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'friends',\n",
       " 'go',\n",
       " 'park',\n",
       " 'like',\n",
       " 'play',\n",
       " 'soccer',\n",
       " 'park',\n",
       " 'fridays',\n",
       " 'go',\n",
       " 'cinema',\n",
       " 'see',\n",
       " 'movie',\n",
       " 'children',\n",
       " 'dont',\n",
       " 'go',\n",
       " 'school',\n",
       " 'weekend',\n",
       " 'day',\n",
       " 'people',\n",
       " 'go',\n",
       " 'hospital',\n",
       " 'sick',\n",
       " 'doctors',\n",
       " 'nurses',\n",
       " 'take',\n",
       " 'care',\n",
       " 'police',\n",
       " 'keep',\n",
       " 'everyone',\n",
       " 'safe',\n",
       " 'happy',\n",
       " 'live',\n",
       " 'city']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = \" \".join([s for s in normalized_sentences]).split()\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(words):\n",
    "    counts = dict()\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'also': 1,\n",
       " 'apartment': 1,\n",
       " 'care': 1,\n",
       " 'children': 1,\n",
       " 'cinema': 1,\n",
       " 'city': 3,\n",
       " 'clark': 1,\n",
       " 'cream': 1,\n",
       " 'day': 1,\n",
       " 'doctors': 1,\n",
       " 'dont': 1,\n",
       " 'eat': 1,\n",
       " 'everyone': 2,\n",
       " 'food': 1,\n",
       " 'fridays': 1,\n",
       " 'friends': 1,\n",
       " 'go': 5,\n",
       " 'grocery': 1,\n",
       " 'happy': 1,\n",
       " 'hospital': 1,\n",
       " 'ice': 1,\n",
       " 'keep': 1,\n",
       " 'letters': 1,\n",
       " 'like': 1,\n",
       " 'live': 2,\n",
       " 'mail': 1,\n",
       " 'monday': 1,\n",
       " 'movie': 1,\n",
       " 'name': 1,\n",
       " 'nurses': 1,\n",
       " 'office': 2,\n",
       " 'park': 2,\n",
       " 'people': 2,\n",
       " 'pizza': 1,\n",
       " 'play': 1,\n",
       " 'police': 1,\n",
       " 'post': 2,\n",
       " 'restaurant': 2,\n",
       " 'safe': 1,\n",
       " 'school': 1,\n",
       " 'see': 1,\n",
       " 'serves': 1,\n",
       " 'shops': 1,\n",
       " 'sick': 1,\n",
       " 'soccer': 1,\n",
       " 'store': 1,\n",
       " 'take': 1,\n",
       " 'tell': 1,\n",
       " 'weekend': 1,\n",
       " 'work': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dictionary = word_count(list_of_words)\n",
    "word_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'also': 0.015625,\n",
       " 'apartment': 0.015625,\n",
       " 'care': 0.015625,\n",
       " 'children': 0.015625,\n",
       " 'cinema': 0.015625,\n",
       " 'city': 0.046875,\n",
       " 'clark': 0.015625,\n",
       " 'cream': 0.015625,\n",
       " 'day': 0.015625,\n",
       " 'doctors': 0.015625,\n",
       " 'dont': 0.015625,\n",
       " 'eat': 0.015625,\n",
       " 'everyone': 0.03125,\n",
       " 'food': 0.015625,\n",
       " 'fridays': 0.015625,\n",
       " 'friends': 0.015625,\n",
       " 'go': 0.078125,\n",
       " 'grocery': 0.015625,\n",
       " 'happy': 0.015625,\n",
       " 'hospital': 0.015625,\n",
       " 'ice': 0.015625,\n",
       " 'keep': 0.015625,\n",
       " 'letters': 0.015625,\n",
       " 'like': 0.015625,\n",
       " 'live': 0.03125,\n",
       " 'mail': 0.015625,\n",
       " 'monday': 0.015625,\n",
       " 'movie': 0.015625,\n",
       " 'name': 0.015625,\n",
       " 'nurses': 0.015625,\n",
       " 'office': 0.03125,\n",
       " 'park': 0.03125,\n",
       " 'people': 0.03125,\n",
       " 'pizza': 0.015625,\n",
       " 'play': 0.015625,\n",
       " 'police': 0.015625,\n",
       " 'post': 0.03125,\n",
       " 'restaurant': 0.03125,\n",
       " 'safe': 0.015625,\n",
       " 'school': 0.015625,\n",
       " 'see': 0.015625,\n",
       " 'serves': 0.015625,\n",
       " 'shops': 0.015625,\n",
       " 'sick': 0.015625,\n",
       " 'soccer': 0.015625,\n",
       " 'store': 0.015625,\n",
       " 'take': 0.015625,\n",
       " 'tell': 0.015625,\n",
       " 'weekend': 0.015625,\n",
       " 'work': 0.03125}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_frequency_of_word_in_text = dict([(w, word_dictionary[w]/len(list_of_words)) for w in word_dictionary])\n",
    "normalized_frequency_of_word_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0234375,\n",
       " 0.0234375,\n",
       " 0.028645833333333332,\n",
       " 0.041666666666666664,\n",
       " 0.03125,\n",
       " 0.01875,\n",
       " 0.020833333333333332,\n",
       " 0.01875,\n",
       " 0.041666666666666664,\n",
       " 0.01953125,\n",
       " 0.028125,\n",
       " 0.028125,\n",
       " 0.03125,\n",
       " 0.015625,\n",
       " 0.01953125,\n",
       " 0.03125]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = lambda x : [sum([normalized_frequency_of_word_in_text.get(a) for a in x.split()])/len(x.split()) for x in x]\n",
    "tf(normalized_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
